{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Investigating patterns in Jeopardy questions\n",
    "\n",
    "We're all familiar with the game of Jeopardy, but if you're not, it is a popular TV show in the US where participants answer questions to win money. It was hosted by the absolute legend Alex Trebek for many years until his unfortunate passing this year. \n",
    "\n",
    "I'm writing this project on New Year's Eve and building on the hypothetical assumption that I would like to compete in Jeopardy. In order to gain any sort of competitive advantage, I'm going to take a look at a dataset of Jeopardy questions to see if I can figure out some patterns that might help me win (again - should I decide to compete). \n",
    "\n",
    "We're going to be using a dataset named jeopardy.csv containing 20000 rows. Here are the columns in the dataset and their explanation (and if you'd like to download it yourself, you can follow think [link](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file)):\n",
    "\n",
    "- Show Number -- the Jeopardy episode number of the show this question was in.\n",
    "- Air Date -- the date the episode aired.\n",
    "- Round -- the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "- Category -- the category of the question.\n",
    "- Value -- the number of dollars answering the question correctly is worth.\n",
    "- Question -- the text of the question.\n",
    "- Answer -- the text of the answer.\n",
    "\n",
    "Let's go ahead and read in our dataset so we can explore its contents a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in dataset\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "\n",
    "# print first 5 rows\n",
    "jeopardy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print columns of jeopardy\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns have spaces in front. Let's get rid of those quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      "Air Date       19999 non-null object\n",
      "Round          19999 non-null object\n",
      "Category       19999 non-null object\n",
      "Value          19999 non-null object\n",
      "Question       19999 non-null object\n",
      "Answer         19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing text and value columns\n",
    "\n",
    "In order to avoid mistakes in our analysis, we're going to normalize all of the text columns (the Question and Answer columns). Essentially, this is to ensure that words with different cases or punctuations aren't considered to be different words when compared. \n",
    "\n",
    "Let's write a function that:\n",
    "\n",
    "- Takes in a string.\n",
    "- Converts the string to lowercase.\n",
    "- Removes all punctuation in the string.\n",
    "- Returns the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text): # takes in string\n",
    "    text = text.lower() # make lower case\n",
    "    text = re.sub('[^A-Za-z0-9\\s]', '', text) # removes punctuation\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text # returns string\n",
    "\n",
    "# apply function to question and answer columns\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text columns are not the only ones needing normalizing here. The Value column should be numeric to allow us to manipulate it more easily, while the Air Date column should be in datetime format, not in string format. \n",
    "\n",
    "For the Value column, let's write a function that can:\n",
    "- Take in a string.\n",
    "- Remove any punctuation in the string.\n",
    "- Convert the string to an integer.\n",
    "- If the conversion has an error, assign 0 instead.\n",
    "- Return the integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_values(text):\n",
    "    text = re.sub('[^A-Za-z0-9\\s]', '', text) # remove punctuation\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception: # if conversion \n",
    "        text = 0\n",
    "    return text\n",
    "\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now quickly change the Air Date column to a datetime column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the answer deducible from the question?\n",
    "\n",
    "Now that our dataset is cleaned up, we're going to try and answer our first question:\n",
    "\n",
    "- How often is the answer deducible from the question?\n",
    "\n",
    "To do so, we need to see how many times words in the answer also occur in the question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that according to our analysis, the mean amount of times the answer is already in the question is 0.059 times, so only about 6% of the time. Consequently, I don't think that we'll be able to rely on certain words in the question being in the answer for our studying strategy for Jeopardy 2021. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often are questions repeats of older ones?\n",
    "\n",
    "We can't completely answer this question, since we only have about 10% of the full Jeopardy question dataset, but we can at least work with what we have. \n",
    "\n",
    "To figure this out, we'll have to:\n",
    "\n",
    "- Sort jeopardy in order of ascending air date.\n",
    "- Maintain a set called terms_used that will be empty initially.\n",
    "- Iterate through each row of jeopardy.\n",
    "- Split clean_question into words, remove any word shorter than 6 characters, and check if each word occurs in terms_used.\n",
    "    - If it does, increment a counter.\n",
    "    - Add each word to terms_used.\n",
    "\n",
    "We're removing words shorter than 6 characters so that we can filter out redundant words like 'the' and 'than', which don't tell us a whole lot about the question unless the question is \"the the the the the than?\"\n",
    "\n",
    "Let's give it a go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    \n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    \n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6876260592169802\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy['question_overlap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our results, there seems to be about a 70% overlap between new questions and terms in old questions. Of course this is not the total amount of questions from Jeopardy, which means that this result is not necessarily significant, but it would give one reason to look into this a bit more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High value vs low value questions\n",
    "\n",
    "Finally, let's say we wanted to study more high value questions instead of low value questions. That would be the perfect way to make more money, right? \n",
    "\n",
    "Well, we can actually figure which terms correspond to high-value questions using a chi-squared test. First, we'll need to narrow down questions into two categories:\n",
    "\n",
    "- Low value -- Any row where Value is less than 800.\n",
    "- High value -- Any row where Value is greater than 800.\n",
    "\n",
    "Then we can loop through each of the terms from the last screen and:\n",
    "\n",
    "- Find the number of low value questions the word occurs in.\n",
    "- Find the number of high value questions the word occurs in.\n",
    "- Find the percentage of questions the word occurs in.\n",
    "- Based on the percentage of questions the word occurs in, find expected counts.\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "Then we can find the words with the biggest differences in usage between high and low value questions by selecting words with the highest associated chi-squared values. We'll just do it with a small sample for now, since doing it for all the words would take a pretty long while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy['high_value'] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def high_low_count(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 2),\n",
       " (1, 2),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (2, 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(high_low_count(word))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we've found the observed counts for a few terms, so now we'll compute the expected counts and the chi-squared value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=0.03188116723440362, pvalue=0.8582887163235293),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=0.06376233446880725, pvalue=0.8006453026878781)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    \n",
    "    expected_high_count = total_prop * high_value_count\n",
    "    expected_low_count = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([expected_high_count, expected_low_count])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like none of the terms had a significant difference between high value and low value rows. Also, the frequences were all below 5 and so our chi-squared test is not as valid. Further analysis would need to be done with terms with higher frequencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "It's looking like Jeopardy questions are a tough nut to crack. We were able to delve into three specific questions:\n",
    "\n",
    "- How often is the answer used in the question?\n",
    "- How often are terms recycled in questions?\n",
    "- Do certain terms in questions relate to more high-value questions?\n",
    "\n",
    "We didn't have much luck in looking through each of these questions, but we did get some indication of terms being recycled, which would warrant further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
